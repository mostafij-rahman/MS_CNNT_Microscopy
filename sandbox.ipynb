{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Check the Python environment used by Jupyter Notebook\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install the tqdm module\n",
    "!{sys.executable} -m pip install tqdm\n",
    "!{sys.executable} -m pip install --upgrade jupyter\n",
    "!{sys.executable} -m pip install --upgrade ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Enable Jupyter widgets extension\n",
    "!{sys.executable} -m jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!{sys.executable} -m jupyter nbextension install --py widgetsnbextension --sys-prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Extract the tar.gz file with progress bar and save files in the same parent directory\n",
    "import tarfile\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Path to your tar.gz file\n",
    "tar_path = '/isilon/ai-data/PublicData/Nonprocessed/Denoising_Planaria.tar.gz'\n",
    "\n",
    "# Get the parent directory of the tar.gz file\n",
    "parent_dir = os.path.dirname(tar_path)\n",
    "\n",
    "# Open the tar.gz file\n",
    "with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "    # Get the total number of files in the tar.gz for the progress bar\n",
    "    total_files = len(tar.getmembers())\n",
    "    print(total_files)\n",
    "    # Extract the tar.gz file with a progress bar\n",
    "    #with tqdm(total=total_files, desc=\"Extracting files\") as pbar:\n",
    "    for member in tar.getmembers():\n",
    "        tar.extract(member, path=parent_dir)\n",
    "        #pbar.update(1)\n",
    "\n",
    "print(\"Extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: List all TIFF files in the extracted directory\n",
    "import os\n",
    "\n",
    "# Directory containing the extracted TIFF files\n",
    "image_dir = '/isilon/ai-data/PublicData/Nonprocessed/Denoising_Planaria/train_data/'\n",
    "\n",
    "# List all TIFF files in the directory\n",
    "tiff_files = os.listdir(image_dir) #[f for f in os.listdir(image_dir) if f.endswith('.npz') or f.endswith('.tif')]\n",
    "\n",
    "print(\"TIFF files found:\", tiff_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load and display the first TIFF image and its shape\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if there are any TIFF files\n",
    "if tiff_files:\n",
    "    # Load the first TIFF image\n",
    "    image_path = os.path.join(image_dir, tiff_files[0])\n",
    "    image = tiff.imread(image_path)\n",
    "    \n",
    "    # Display the shape of the image\n",
    "    print(\"Shape of the image:\", image.shape)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Microscopy Image')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No TIFF files found in the extracted directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def split_h5_file(input_file, output_dir, output_file1_name, output_file2_name):\n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct the full output file paths\n",
    "    output_file1_path = os.path.join(output_dir, output_file1_name)\n",
    "    output_file2_path = os.path.join(output_dir, output_file2_name)\n",
    "    \n",
    "    test_data = {}\n",
    "    train_data = {}\n",
    "\n",
    "    # Open the input HDF5 file in read mode\n",
    "    with h5py.File(input_file, 'r') as infile:\n",
    "        keys = list(infile.keys())\n",
    "\n",
    "        # Determine the split index\n",
    "        split_index = 25\n",
    "\n",
    "        # Process top-level groups and datasets\n",
    "        for i, key in enumerate(keys):\n",
    "            item = infile[key]\n",
    "            if isinstance(item, h5py.Group):\n",
    "                if i < split_index:\n",
    "                    test_data[key] = {}\n",
    "                else:\n",
    "                    train_data[key] = {}\n",
    "                for subkey in item.keys():\n",
    "                    subitem = item[subkey]\n",
    "                    if isinstance(subitem, h5py.Dataset):\n",
    "                        data = subitem[:]\n",
    "                        if i < split_index:\n",
    "                            test_data[key][subkey] = data\n",
    "                            print(f\"Added {key}/{subkey} to test_data\")\n",
    "                        else:\n",
    "                            train_data[key][subkey] = data\n",
    "                            print(f\"Added {key}/{subkey} to train_data\")\n",
    "                    else:\n",
    "                        print(f\"Skipped {key}/{subkey} as it is not a dataset\")\n",
    "            elif isinstance(item, h5py.Dataset):\n",
    "                data = item[:]\n",
    "                if i < split_index:\n",
    "                    test_data[key] = data\n",
    "                    print(f\"Added {key} to test_data\")\n",
    "                else:\n",
    "                    train_data[key] = data\n",
    "                    print(f\"Added {key} to train_data\")\n",
    "            else:\n",
    "                print(f\"Skipped {key} as it is not a group or dataset\")\n",
    "\n",
    "    def save_data(outfile, data_dict):\n",
    "        for key, data in data_dict.items():\n",
    "            if isinstance(data, dict):\n",
    "                group = outfile.create_group(key)\n",
    "                save_data(group, data)\n",
    "            else:\n",
    "                if data.dtype.kind == 'U':  # Check if data type is Unicode string\n",
    "                    data = np.array(data, dtype='S')  # Convert to byte string\n",
    "                outfile.create_dataset(key, data=data)\n",
    "                #print(f\"Saved {key} to {outfile.filename}\")\n",
    "\n",
    "    # Save the split data into the new HDF5 files\n",
    "    with h5py.File(output_file1_path, 'w') as outfile1:\n",
    "        save_data(outfile1, test_data)\n",
    "            \n",
    "    with h5py.File(output_file2_path, 'w') as outfile2:\n",
    "        save_data(outfile2, train_data)\n",
    "\n",
    "# Usage example\n",
    "root_dir = '/isilon/lab-xue/publications/CNNT_paper/data/micro_datasets_tvt_split/'\n",
    "input_file = os.path.join(root_dir, 'Ryo_tile_new_train.h5')\n",
    "output_file1_name = 'Ryo_tile_new_ft_train.h5'\n",
    "output_file2_name = 'Ryo_tile_new_backbone_train.h5'\n",
    "\n",
    "split_h5_file(input_file, root_dir, output_file1_name, output_file2_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '/isilon/lab-xue/publications/CNNT_paper/data/micro_datasets_tvt_split/Ryo_tile_new_ft_train.h5'\n",
    "# Open the input HDF5 file in read mode\n",
    "with h5py.File(test_file, 'r') as test_data_new:\n",
    "    print(len(test_data_new))\n",
    "    print(test_data_new)\n",
    "    print(test_data_new.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n",
      "tensor(0.9219)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "preds = torch.rand([3, 1, 256, 256])\n",
    "target = preds * 0.75\n",
    "metric = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "values = [ ]\n",
    "for _ in range(10):\n",
    "    ssim = metric(preds, target)\n",
    "    print(ssim)\n",
    "    values.append(ssim)\n",
    "fig_, ax_ = metric.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "root_dir = '/isilon/lab-xue/publications/CNNT_paper/data/micro_datasets_tvt_split/'\n",
    "input_file = os.path.join(root_dir, 'Base_All_new_train.h5')\n",
    "output_file = os.path.join('/home/rahmanm9/micro_datasets_tvt_split_float32/', 'Base_All_new_train.h5')\n",
    "\n",
    "with h5py.File(input_file, 'r') as infile, h5py.File(output_file, 'w') as outfile:\n",
    "    keys = list(infile.keys())\n",
    "    \n",
    "    # Start measuring time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for key in keys:\n",
    "        noisy_data = np.asarray(infile[key + \"/noisy_im\"], dtype=np.float32)\n",
    "        clean_data = np.asarray(infile[key + \"/clean_im\"], dtype=np.float32)\n",
    "        \n",
    "        # Create groups and datasets in the output file\n",
    "        grp = outfile.create_group(key)\n",
    "        grp.create_dataset(\"noisy_im\", data=noisy_data, dtype='float32')\n",
    "        grp.create_dataset(\"clean_im\", data=clean_data, dtype='float32')\n",
    "    \n",
    "    # End measuring time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate and print elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM2D: 0.9218931198120117\n",
      "SSIM3D: 0.9600000381469727\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Metric\n",
    "from torch import Tensor\n",
    "from typing import Any, List, Optional, Sequence, Tuple, Union, Literal\n",
    "\n",
    "\n",
    "def _gaussian_kernel_3d(channel: int, kernel_size: Sequence[int], sigma: Sequence[float], dtype: torch.dtype, device: torch.device) -> Tensor:\n",
    "    \"\"\"Creates a 3D Gaussian kernel.\"\"\"\n",
    "    coords = [torch.arange(size, dtype=dtype, device=device) for size in kernel_size]\n",
    "    coords = [coord - (size - 1) / 2 for coord, size in zip(coords, kernel_size)]\n",
    "    kernel = torch.exp(-0.5 * sum((coord ** 2 / s ** 2 for coord, s in zip(coords, sigma))))\n",
    "    kernel = kernel / kernel.sum()\n",
    "    kernel = kernel.expand(channel, 1, *kernel_size)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def _reflection_pad_3d(x: Tensor, pad_d: int, pad_w: int, pad_h: int) -> Tensor:\n",
    "    \"\"\"Pads a 5D tensor with reflection padding.\"\"\"\n",
    "    return F.pad(x, (pad_w, pad_w, pad_h, pad_h, pad_d, pad_d), mode='reflect')\n",
    "\n",
    "\n",
    "def _ssim_check_inputs(preds: Tensor, target: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Update and returns variables required to compute Structural Similarity Index Measure.\"\"\"\n",
    "    if preds.dtype != target.dtype:\n",
    "        target = target.to(preds.dtype)\n",
    "    if preds.shape != target.shape:\n",
    "        raise ValueError(f\"Expected `preds` and `target` to have the same shape, but got {preds.shape} and {target.shape}.\")\n",
    "    if len(preds.shape) != 5:\n",
    "        raise ValueError(f\"Expected `preds` and `target` to have BxCxDxHxW shape, but got {preds.shape}.\")\n",
    "    return preds, target\n",
    "\n",
    "\n",
    "class StructuralSimilarityIndexMeasure3D(Metric):\n",
    "    \"\"\"Compute Structural Similarity Index Measure (SSIM) for 3D images.\"\"\"\n",
    "\n",
    "    higher_is_better: bool = True\n",
    "    is_differentiable: bool = True\n",
    "    full_state_update: bool = False\n",
    "    plot_lower_bound: float = 0.0\n",
    "    plot_upper_bound: float = 1.0\n",
    "\n",
    "    preds: List[Tensor]\n",
    "    target: List[Tensor]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        gaussian_kernel: bool = True,\n",
    "        sigma: Union[float, Sequence[float]] = 1.5,\n",
    "        kernel_size: Union[int, Sequence[int]] = 11,\n",
    "        reduction: Literal[\"elementwise_mean\", \"sum\", \"none\", None] = \"elementwise_mean\",\n",
    "        data_range: Optional[Union[float, Tuple[float, float]]] = None,\n",
    "        k1: float = 0.01,\n",
    "        k2: float = 0.03,\n",
    "        return_full_image: bool = False,\n",
    "        return_contrast_sensitivity: bool = False,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        valid_reduction = (\"elementwise_mean\", \"sum\", \"none\", None)\n",
    "        if reduction not in valid_reduction:\n",
    "            raise ValueError(f\"Argument `reduction` must be one of {valid_reduction}, but got {reduction}\")\n",
    "\n",
    "        if reduction in (\"elementwise_mean\", \"sum\"):\n",
    "            self.add_state(\"similarity\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        else:\n",
    "            self.add_state(\"similarity\", default=[], dist_reduce_fx=\"cat\")\n",
    "\n",
    "        self.add_state(\"total\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "        if return_contrast_sensitivity or return_full_image:\n",
    "            self.add_state(\"image_return\", default=[], dist_reduce_fx=\"cat\")\n",
    "\n",
    "        self.gaussian_kernel = gaussian_kernel\n",
    "        self.sigma = sigma\n",
    "        self.kernel_size = kernel_size\n",
    "        self.reduction = reduction\n",
    "        self.data_range = data_range\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.return_full_image = return_full_image\n",
    "        self.return_contrast_sensitivity = return_contrast_sensitivity\n",
    "\n",
    "    def update(self, preds: Tensor, target: Tensor) -> None:\n",
    "        \"\"\"Update state with predictions and targets.\"\"\"\n",
    "        preds, target = _ssim_check_inputs(preds, target)\n",
    "        similarity_pack = self._ssim_update(preds, target)\n",
    "\n",
    "        if isinstance(similarity_pack, tuple):\n",
    "            similarity, image = similarity_pack\n",
    "        else:\n",
    "            similarity = similarity_pack\n",
    "\n",
    "        if self.return_contrast_sensitivity or self.return_full_image:\n",
    "            self.image_return.append(image)\n",
    "\n",
    "        if self.reduction in (\"elementwise_mean\", \"sum\"):\n",
    "            self.similarity += similarity.sum()\n",
    "            self.total += preds.shape[0]\n",
    "        else:\n",
    "            self.similarity.append(similarity)\n",
    "\n",
    "    def compute(self) -> Union[Tensor, Tuple[Tensor, Tensor]]:\n",
    "        \"\"\"Compute SSIM over state.\"\"\"\n",
    "        if self.reduction == \"elementwise_mean\":\n",
    "            similarity = self.similarity / self.total\n",
    "        elif self.reduction == \"sum\":\n",
    "            similarity = self.similarity\n",
    "        else:\n",
    "            similarity = torch.cat(self.similarity, dim=0)\n",
    "\n",
    "        if self.return_contrast_sensitivity or self.return_full_image:\n",
    "            image_return = torch.cat(self.image_return, dim=0)\n",
    "            return similarity, image_return\n",
    "\n",
    "        return similarity\n",
    "\n",
    "    def plot(\n",
    "        self, val: Optional[Union[Tensor, Sequence[Tensor]]] = None, ax: Optional[Any] = None\n",
    "    ) -> Any:\n",
    "        \"\"\"Plot a single or multiple values from the metric.\"\"\"\n",
    "        return self._plot(val, ax)\n",
    "\n",
    "    def _ssim_update(\n",
    "        self,\n",
    "        preds: Tensor,\n",
    "        target: Tensor\n",
    "    ) -> Union[Tensor, Tuple[Tensor, Tensor]]:\n",
    "        \"\"\"Compute Structural Similarity Index Measure.\"\"\"\n",
    "        if not isinstance(self.kernel_size, Sequence):\n",
    "            self.kernel_size = 3 * [self.kernel_size]\n",
    "        if not isinstance(self.sigma, Sequence):\n",
    "            self.sigma = 3 * [self.sigma]\n",
    "\n",
    "        if len(self.kernel_size) != 3:\n",
    "            raise ValueError(f\"`kernel_size` should have 3 dimensions, but got {len(self.kernel_size)}\")\n",
    "        if len(self.sigma) != 3:\n",
    "            raise ValueError(f\"`sigma` should have 3 dimensions, but got {len(self.sigma)}\")\n",
    "\n",
    "        if self.return_full_image and self.return_contrast_sensitivity:\n",
    "            raise ValueError(\"Arguments `return_full_image` and `return_contrast_sensitivity` are mutually exclusive.\")\n",
    "\n",
    "        if any(x % 2 == 0 or x <= 0 for x in self.kernel_size):\n",
    "            raise ValueError(f\"Expected `kernel_size` to have odd positive numbers. Got {self.kernel_size}\")\n",
    "\n",
    "        if any(y <= 0 for y in self.sigma):\n",
    "            raise ValueError(f\"Expected `sigma` to have positive numbers. Got {self.sigma}\")\n",
    "\n",
    "        if self.data_range is None:\n",
    "            self.data_range = max(preds.max() - preds.min(), target.max() - target.min())\n",
    "        elif isinstance(self.data_range, tuple):\n",
    "            preds = torch.clamp(preds, min=self.data_range[0], max=self.data_range[1])\n",
    "            target = torch.clamp(target, min=self.data_range[0], max=self.data_range[1])\n",
    "            self.data_range = self.data_range[1] - self.data_range[0]\n",
    "\n",
    "        print(f\"Data Range: {self.data_range}\")\n",
    "\n",
    "        c1 = (self.k1 * self.data_range) ** 2\n",
    "        c2 = (self.k2 * self.data_range) ** 2\n",
    "        device = preds.device\n",
    "\n",
    "        print(f\"C1: {c1}, C2: {c2}\")\n",
    "\n",
    "        channel = preds.size(1)\n",
    "        dtype = preds.dtype\n",
    "        gauss_kernel_size = [int(3.5 * s + 0.5) * 2 + 1 for s in self.sigma]\n",
    "\n",
    "        pad_h = (gauss_kernel_size[0] - 1) // 2\n",
    "        pad_w = (gauss_kernel_size[1] - 1) // 2\n",
    "        pad_d = (gauss_kernel_size[2] - 1) // 2\n",
    "\n",
    "        preds = _reflection_pad_3d(preds, pad_d, pad_w, pad_h)\n",
    "        target = _reflection_pad_3d(target, pad_d, pad_w, pad_h)\n",
    "\n",
    "        if self.gaussian_kernel:\n",
    "            kernel = _gaussian_kernel_3d(channel, gauss_kernel_size, self.sigma, dtype, device)\n",
    "        else:\n",
    "            kernel = torch.ones((channel, 1, *self.kernel_size), dtype=dtype, device=device) / torch.prod(\n",
    "                torch.tensor(self.kernel_size, dtype=dtype, device=device)\n",
    "            )\n",
    "\n",
    "        input_list = torch.cat((preds, target, preds * preds, target * target, preds * target))\n",
    "\n",
    "        outputs = F.conv3d(input_list, kernel, groups=channel)\n",
    "\n",
    "        output_list = outputs.split(preds.shape[0])\n",
    "\n",
    "        mu_pred = output_list[0]\n",
    "        mu_target = output_list[1]\n",
    "        mu_pred_sq = mu_pred.pow(2)\n",
    "        mu_target_sq = mu_target.pow(2)\n",
    "        mu_pred_target = mu_pred * mu_target\n",
    "\n",
    "        sigma_pred_sq = torch.clamp(output_list[2] - mu_pred_sq, min=0.0)\n",
    "        sigma_target_sq = torch.clamp(output_list[3] - mu_target_sq, min=0.0)\n",
    "        sigma_pred_target = torch.clamp(output_list[4] - mu_pred_target, min=0.0)\n",
    "\n",
    "        print(f\"mu_pred: {mu_pred.mean().item()}, mu_target: {mu_target.mean().item()}, mu_pred_target: {mu_pred_target.mean().item()}\")\n",
    "        print(f\"sigma_pred_sq: {sigma_pred_sq.mean().item()}, sigma_target_sq: {sigma_target_sq.mean().item()}, sigma_pred_target: {sigma_pred_target.mean().item()}\")\n",
    "\n",
    "        upper = 2 * sigma_pred_target.to(dtype) + c2\n",
    "        lower = (sigma_pred_sq + sigma_target_sq).to(dtype) + c2\n",
    "\n",
    "        print(f\"Upper: {upper.mean().item()}, Lower: {lower.mean().item()}\")\n",
    "\n",
    "        ssim_idx_full_image = ((2 * mu_pred_target + c1) * upper) / ((mu_pred_sq + mu_target_sq + c1) * lower)\n",
    "\n",
    "        ssim_idx = ssim_idx_full_image[..., pad_h:-pad_h, pad_w:-pad_w, pad_d:-pad_d]\n",
    "\n",
    "        if self.return_contrast_sensitivity:\n",
    "            contrast_sensitivity = upper / lower\n",
    "            contrast_sensitivity = contrast_sensitivity[..., pad_h:-pad_h, pad_w:-pad_w, pad_d:-pad_d]\n",
    "            return ssim_idx.reshape(ssim_idx.shape[0], -1).mean(-1), contrast_sensitivity.reshape(\n",
    "                contrast_sensitivity.shape[0], -1\n",
    "            ).mean(-1)\n",
    "\n",
    "        if self.return_full_image:\n",
    "            return ssim_idx.reshape(ssim_idx.shape[0], -1).mean(-1), ssim_idx_full_image\n",
    "\n",
    "        return ssim_idx.reshape(ssim_idx.shape[0], -1).mean(-1)\n",
    "\n",
    "\n",
    "# Example Usage for 3D SSIM\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ssim3d = StructuralSimilarityIndexMeasure3D(data_range=1.0).to(device)\n",
    "\n",
    "    # Example 3D tensors (batch_size, channels, depth, height, width)\n",
    "    preds = torch.rand([3, 1, 32, 256, 256], device=device)\n",
    "    target = preds * 0.75\n",
    "\n",
    "    # Update and compute SSIM\n",
    "    ssim3d.update(preds, target)\n",
    "    ssim_value = ssim3d.compute()\n",
    "\n",
    "    print(f\"SSIM3D: {ssim_value.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
